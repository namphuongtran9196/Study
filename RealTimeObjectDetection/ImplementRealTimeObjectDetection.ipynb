{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ImplementRealTimeObjectDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SFnvBiUKu5al"
      ],
      "authorship_tag": "ABX9TyOX5hD9aJzMp3sz+fDw003O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namphuongtran9196/RealTimeObjectDetection_SimpleObject/blob/master/ImplementRealTimeObjectDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0oYOs7Ob6n6"
      },
      "source": [
        "###My work base on two video youtube:\n",
        "\n",
        "https://youtu.be/pDXdlXlaCco\n",
        "https://youtu.be/qJ6gKzGleRU\n",
        "\n",
        "If it useful for you, please like and subcribe their youtube channel.\n",
        "\n",
        "*Many thanks to Mr. Nicholas Renotte for Object detection tutorial and Mì AI for helping me using webcam on colab.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS76jEz-BAN_"
      },
      "source": [
        "### Install tesorflow version 2.0, tf_slim and pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBLsFt-9M4jK",
        "outputId": "8679c7ee-1400-4dde-b449-26f49e47a65b"
      },
      "source": [
        "!pip install -U --pre tensorflow==\"2.0\"\n",
        "!pip install tf_slim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/5c/f1d66de5dde6f3ff528f6ea1fd0757a0e594d17debb3ec7f82daa967ea9a/tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 52kB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (0.2.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.1.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.19.5)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=e51843ffccd9aa8f17a7672f1494c3ce30a4f9bd85a6ab85823783b095d41895\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n",
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50mraP_qM9Ha",
        "outputId": "99ee3712-d57b-4e0a-c837-85cde87a0d84"
      },
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools) (0.29.22)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools) (54.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHxUkrlAMIf1"
      },
      "source": [
        "# Create clone tensorflow/models for install library and model tranning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbZSVohzM_Uk",
        "outputId": "4c35656c-5f66-47bf-82f6-657de391e83d"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2589, done.\u001b[K\n",
            "remote: Counting objects: 100% (2589/2589), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2143/2143), done.\u001b[K\n",
            "remote: Total 2589 (delta 645), reused 1225 (delta 414), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2589/2589), 32.52 MiB | 35.28 MiB/s, done.\n",
            "Resolving deltas: 100% (645/645), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxy8kUohMdzj"
      },
      "source": [
        "## Install object_detection library and others library required"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO-zfl3CNAtV"
      },
      "source": [
        "%%bash\n",
        "cd models/research\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_WabgVNuswp"
      },
      "source": [
        "#copy setup.py file to models/research\n",
        "!cp models/research/object_detection/packages/tf2/setup.py models/research/setup.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPoFkcAtNQJW",
        "outputId": "9bff9c6a-c561-4954-91ea-2bbeee585672"
      },
      "source": [
        "%%bash\n",
        "cd models/research\n",
        "pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz\n",
            "Collecting apache-beam\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/e7/d6e5a3786d9a037a38af966bf154bcd6cb3cbea2edffda00cf6c417cc9a2/apache_beam-2.28.0-cp37-cp37m-manylinux2010_x86_64.whl (9.0MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.22)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official\n",
            "  Downloading https://files.pythonhosted.org/packages/57/4a/23a08f8fd2747867ee223612e219eeb0d11c36116601d99b55ef3c72e707/tf_models_official-2.4.0-py2.py3-none-any.whl (1.1MB)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "Collecting pyarrow<3.0.0,>=0.15.1\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/8d/c002e27767595f22aa09ed0d364327922f673d12b36526c967a2bf6b2ed7/pyarrow-2.0.0-cp37-cp37m-manylinux2014_x86_64.whl (17.7MB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.3)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: numpy<1.20.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "Collecting mock<3.0.0,>=1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading https://files.pythonhosted.org/packages/c5/c7/9ef9fda5e178aa5f5cda00c0d7505749506c540f9caf876d23c6cf915bf9/fastavro-1.3.5-cp37-cp37m-manylinux2014_x86_64.whl (2.2MB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (54.2.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Collecting tensorflow>=2.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/70/dc/e8c5e7983866fa4ef3fd619faa35f660b95b01a2ab62b3884f038ccab542/tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3MB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.11.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "Collecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/6d/92f377bece9b0ec9c893081dbe073a65b38d7ac12ef572b8f70554d08760/opencv_python_headless-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (37.6MB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n",
            "Collecting pbr>=0.11\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Collecting tensorboard~=2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/64/21/eebd23060763fedeefb78bc2b286e00fa1d8abda6f70efa2ee08c28af0d4/tensorboard-2.4.1-py3-none-any.whl (10.6MB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/74/7e/622d9849abf3afb81e482ffc170758742e392ee129ce1540611199a59237/tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462kB)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.5)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.28.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.29.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection, avro-python3, future, dill, seqeval, py-cpuinfo\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1643821 sha256=6d28de42895e4ab7e147ab87a1d938559cc22887fbb6c9727bc8b952eb8a7a2f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gc4c0528/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=0bd6aa48dfe3e978362991ac5c05acc40b964e8ae5376b03bf8f117823021168\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3\n",
            "  Building wheel for future (setup.py): started\n",
            "  Building wheel for future (setup.py): finished with status 'done'\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=0e4bc462a2bb291eab99cddec2c42240dcbd38e09cc83de20ecb5269b7b1ef3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78532 sha256=b954446899d53f56fe029965becc1fa06038f921e50be84ae700fe42a1bb46d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=6ab198cb0bc8e6d99e2412a2fc0926eec0e90903ccd9bd05acb92a720ac43c9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for py-cpuinfo (setup.py): started\n",
            "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22245 sha256=2d675d92fc94626c19db5864c12b9e30cdc6645f90b7d8fec0a66f090bd349ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
            "Successfully built object-detection avro-python3 future dill seqeval py-cpuinfo\n",
            "Installing collected packages: avro-python3, future, pyarrow, requests, hdfs, dill, pbr, mock, fastavro, apache-beam, lvis, gast, tensorboard, tensorflow-estimator, tensorflow, tensorflow-model-optimization, pyyaml, seqeval, sentencepiece, dataclasses, py-cpuinfo, opencv-python-headless, tensorflow-addons, tf-models-official, object-detection\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: pyarrow 3.0.0\n",
            "    Uninstalling pyarrow-3.0.0:\n",
            "      Successfully uninstalled pyarrow-3.0.0\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: dill 0.3.3\n",
            "    Uninstalling dill-0.3.3:\n",
            "      Successfully uninstalled dill-0.3.3\n",
            "  Found existing installation: gast 0.2.2\n",
            "    Uninstalling gast-0.2.2:\n",
            "      Successfully uninstalled gast-0.2.2\n",
            "  Found existing installation: tensorboard 2.0.2\n",
            "    Uninstalling tensorboard-2.0.2:\n",
            "      Successfully uninstalled tensorboard-2.0.2\n",
            "  Found existing installation: tensorflow-estimator 2.0.1\n",
            "    Uninstalling tensorflow-estimator-2.0.1:\n",
            "      Successfully uninstalled tensorflow-estimator-2.0.1\n",
            "  Found existing installation: tensorflow 2.0.0\n",
            "    Uninstalling tensorflow-2.0.0:\n",
            "      Successfully uninstalled tensorflow-2.0.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed apache-beam-2.28.0 avro-python3-1.10.2 dataclasses-0.6 dill-0.3.1.1 fastavro-1.3.5 future-0.18.2 gast-0.3.3 hdfs-2.6.0 lvis-0.5.3 mock-2.0.0 object-detection-0.1 opencv-python-headless-4.5.1.48 pbr-5.5.1 py-cpuinfo-8.0.0 pyarrow-2.0.0 pyyaml-5.4.1 requests-2.25.1 sentencepiece-0.1.95 seqeval-1.2.2 tensorboard-2.4.1 tensorflow-2.4.1 tensorflow-addons-0.12.1 tensorflow-estimator-2.4.0 tensorflow-model-optimization-0.5.0 tf-models-official-2.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.\n",
            "ERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\n",
            "ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\n",
            "ERROR: apache-beam 2.28.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g8PTK9HN7gQ"
      },
      "source": [
        "# Create workspace for real time object detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXCWL98tyiQu"
      },
      "source": [
        "!mkdir RealTimeObjectDetection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE5P-PDiy5ay"
      },
      "source": [
        "!mkdir RealTimeObjectDetection/scripts\n",
        "!mkdir RealTimeObjectDetection/workspace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEiD_gAKzGvc"
      },
      "source": [
        "%%bash\n",
        "cd RealTimeObjectDetection/workspace\n",
        "mkdir annotations\n",
        "mkdir models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggEANjFw0bpy"
      },
      "source": [
        "SCRIPTS_PATH = 'RealTimeObjectDetection/scripts'\n",
        "WORKSPACE_PATH = 'RealTimeObjectDetection/workspace'\n",
        "MODEL_PATH = WORKSPACE_PATH + '/models'\n",
        "ANNOTATION_PATH = WORKSPACE_PATH + '/annotations'\n",
        "IMAGE_PATH = WORKSPACE_PATH +'/images'\n",
        "APIMODEL_PATH = '/content/models'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUbq0nHkNEYX"
      },
      "source": [
        "# Download model from tensorflow models zoo 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEpM_H4FaEq8"
      },
      "source": [
        "def get_model(model_name):\n",
        "  base_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\n",
        "  model_file = base_url+ model_name + '.tar.gz'\n",
        "  !gdown $model_file\n",
        "  file_name = model_name+'.tar.gz'\n",
        "  return file_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Au0wgNJaElS",
        "outputId": "8d37b049-6fe0-42ff-e50a-d670bcbb8b44"
      },
      "source": [
        "CUSTOM_MODEL_NAME = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n",
        "model = get_model(CUSTOM_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n",
            "To: /content/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n",
            "100% 212M/212M [00:03<00:00, 61.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB0IEIsUgrYU"
      },
      "source": [
        "!gunzip $model\n",
        "!tar -xf $CUSTOM_MODEL_NAME\\.tar\n",
        "!rm $CUSTOM_MODEL_NAME\\.tar\n",
        "!mv $CUSTOM_MODEL_NAME $MODEL_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LssdnWsseL3"
      },
      "source": [
        "CUSTOM_MODEL_PATH =MODEL_PATH +'/' + CUSTOM_MODEL_NAME\n",
        "CONFIG_PATH = CUSTOM_MODEL_PATH+'/pipeline.config'\n",
        "CHECKPOINT_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDTJewzmOGbF"
      },
      "source": [
        "# Download data for tranning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWkN3ZSthaZl"
      },
      "source": [
        "About datase:\n",
        "\n",
        "This dataset create from my room, and the dataset is collected not too general.\n",
        "Its classfies bottle, cat(mochi), sunglasses, remote, controller"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ8vyfNovDaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7f6257-4a93-428b-cef0-d466b8cf81c6"
      },
      "source": [
        "%%bash\n",
        "gdown --id 1yEWYA_vma1AQBtOA75iclv5kvdwXE9Ow\n",
        "unrar x images.rar\n",
        "rm images.rar\n",
        "mv images RealTimeObjectDetection/workspace/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from images.rar\n",
            "\n",
            "Creating    images                                                    OK\n",
            "Creating    images/test                                               OK\n",
            "Extracting  images/test/IMG_4037.jpg                                     \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4037.xml                                     \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4040.jpg                                     \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4040.xml                                     \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4046.jpg                                     \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4046.xml                                     \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4063.jpg                                     \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4063.xml                                     \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4064.jpg                                     \b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4064.xml                                     \b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4596.jpg                                     \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4596.xml                                     \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4601.jpg                                     \b\b\b\b 11%\b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4601.xml                                     \b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4605.jpg                                     \b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4605.xml                                     \b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4606.jpg                                     \b\b\b\b 13%\b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4606.xml                                     \b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4608.jpg                                     \b\b\b\b 14%\b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4608.xml                                     \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4611.jpg                                     \b\b\b\b 15%\b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4611.xml                                     \b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4615.jpg                                     \b\b\b\b 16%\b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4615.xml                                     \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4616.jpg                                     \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4616.xml                                     \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4618.jpg                                     \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4618.xml                                     \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4621.jpg                                     \b\b\b\b 19%\b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4621.xml                                     \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4627.jpg                                     \b\b\b\b 20%\b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4627.xml                                     \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4630.jpg                                     \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4630.xml                                     \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4637.jpg                                     \b\b\b\b 23%\b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4637.xml                                     \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4639.jpg                                     \b\b\b\b 24%\b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4639.xml                                     \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4641.jpg                                     \b\b\b\b 25%\b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4641.xml                                     \b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4645.jpg                                     \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4645.xml                                     \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4650.jpg                                     \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4650.xml                                     \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4652.jpg                                     \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4652.xml                                     \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4657.jpg                                     \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4657.xml                                     \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4660.jpg                                     \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  images/test/IMG_4660.xml                                     \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Creating    images/train                                              OK\n",
            "Extracting  images/train/IMG_4065.jpg                                    \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4065.xml                                    \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4066.jpg                                    \b\b\b\b 31%\b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4066.xml                                    \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4067.jpg                                    \b\b\b\b 32%\b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4067.xml                                    \b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4068.jpg                                    \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4068.xml                                    \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4253.jpg                                    \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4253.xml                                    \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4254.jpg                                    \b\b\b\b 36%\b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4254.xml                                    \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4259.jpg                                    \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4259.xml                                    \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4298.jpg                                    \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4298.xml                                    \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4349.jpg                                    \b\b\b\b 38%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4349.xml                                    \b\b\b\b 38%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4352.jpg                                    \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4352.xml                                    \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4360.jpg                                    \b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4360.xml                                    \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4362.jpg                                    \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4362.xml                                    \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4365.jpg                                    \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4365.xml                                    \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4368.jpg                                    \b\b\b\b 43%\b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4368.xml                                    \b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4375.jpg                                    \b\b\b\b 44%\b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4375.xml                                    \b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4379.jpg                                    \b\b\b\b 46%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4379.xml                                    \b\b\b\b 46%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4380.jpg                                    \b\b\b\b 46%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4380.xml                                    \b\b\b\b 46%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4381.jpg                                    \b\b\b\b 46%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4381.xml                                    \b\b\b\b 46%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4402.jpg                                    \b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4402.xml                                    \b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4404.jpg                                    \b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4404.xml                                    \b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4467.jpg                                    \b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4467.xml                                    \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4474.jpg                                    \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4474.xml                                    \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4479.jpg                                    \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4479.xml                                    \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4480.jpg                                    \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4480.xml                                    \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4597.jpg                                    \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4597.xml                                    \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4598.jpg                                    \b\b\b\b 56%\b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4598.xml                                    \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4599.jpg                                    \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4599.xml                                    \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4600.jpg                                    \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4600.xml                                    \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4602.jpg                                    \b\b\b\b 59%\b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4602.xml                                    \b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4603.jpg                                    \b\b\b\b 60%\b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4603.xml                                    \b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4604.jpg                                    \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4604.xml                                    \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4607.jpg                                    \b\b\b\b 62%\b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4607.xml                                    \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4609.jpg                                    \b\b\b\b 63%\b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4609.xml                                    \b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4610.jpg                                    \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4610.xml                                    \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4612.jpg                                    \b\b\b\b 65%\b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4612.xml                                    \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4613.jpg                                    \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4613.xml                                    \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4614.jpg                                    \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4614.xml                                    \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4617.jpg                                    \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4617.xml                                    \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4619.jpg                                    \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4619.xml                                    \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4620.jpg                                    \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4620.xml                                    \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4622.jpg                                    \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4622.xml                                    \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4623.jpg                                    \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4623.xml                                    \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4624.jpg                                    \b\b\b\b 73%\b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4624.xml                                    \b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4625.jpg                                    \b\b\b\b 74%\b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4625.xml                                    \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4626.jpg                                    \b\b\b\b 75%\b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4626.xml                                    \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4628.jpg                                    \b\b\b\b 76%\b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4628.xml                                    \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4629.jpg                                    \b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4629.xml                                    \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4631.jpg                                    \b\b\b\b 79%\b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4631.xml                                    \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4632.jpg                                    \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4632.xml                                    \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4633.jpg                                    \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4633.xml                                    \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4634.jpg                                    \b\b\b\b 82%\b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4634.xml                                    \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4635.jpg                                    \b\b\b\b 83%\b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4635.xml                                    \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4636.jpg                                    \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4636.xml                                    \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4638.jpg                                    \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4638.xml                                    \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4640.jpg                                    \b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4640.xml                                    \b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4642.jpg                                    \b\b\b\b 87%\b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4642.xml                                    \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4643.jpg                                    \b\b\b\b 88%\b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4643.xml                                    \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4644.jpg                                    \b\b\b\b 89%\b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4644.xml                                    \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4646.jpg                                    \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4646.xml                                    \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4647.jpg                                    \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4647.xml                                    \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4648.jpg                                    \b\b\b\b 93%\b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4648.xml                                    \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4649.jpg                                    \b\b\b\b 94%\b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4649.xml                                    \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4651.jpg                                    \b\b\b\b 96%\b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4651.xml                                    \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4653.jpg                                    \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4653.xml                                    \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4654.jpg                                    \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4654.xml                                    \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4655.jpg                                    \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4655.xml                                    \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4656.jpg                                    \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4656.xml                                    \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4658.jpg                                    \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4658.xml                                    \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4659.jpg                                    \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4659.xml                                    \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4661.jpg                                    \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  images/train/IMG_4661.xml                                    \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yEWYA_vma1AQBtOA75iclv5kvdwXE9Ow\n",
            "To: /content/images.rar\n",
            "\r0.00B [00:00, ?B/s]\r4.72MB [00:00, 11.0MB/s]\r17.3MB [00:00, 13.5MB/s]\r25.7MB [00:01, 15.1MB/s]\r34.1MB [00:01, 17.8MB/s]\r42.5MB [00:01, 19.6MB/s]\r59.2MB [00:02, 23.9MB/s]\r69.6MB [00:02, 30.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YYnWNbD8tJj"
      },
      "source": [
        "# generate_tfrecord.py for create tfrecord to feed input into model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bssnKL850j75"
      },
      "source": [
        "import os\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUNS8XINuEFw",
        "outputId": "0f2965c6-41c4-4e26-8fb0-ff87ee9fd1f9"
      },
      "source": [
        "%%writefile RealTimeObjectDetection/scripts/generate_tfrecord.py\n",
        "\"\"\" Sample TensorFlow XML-to-TFRecord converter\n",
        "usage: generate_tfrecord.py [-h] [-x XML_DIR] [-l LABELS_PATH] [-o OUTPUT_PATH] [-i IMAGE_DIR] [-c CSV_PATH]\n",
        "optional arguments:\n",
        "  -h, --help            show this help message and exit\n",
        "  -x XML_DIR, --xml_dir XML_DIR\n",
        "                        Path to the folder where the input .xml files are stored.\n",
        "  -l LABELS_PATH, --labels_path LABELS_PATH\n",
        "                        Path to the labels (.pbtxt) file.\n",
        "  -o OUTPUT_PATH, --output_path OUTPUT_PATH\n",
        "                        Path of output TFRecord (.record) file.\n",
        "  -i IMAGE_DIR, --image_dir IMAGE_DIR\n",
        "                        Path to the folder where the input image files are stored. Defaults to the same directory as XML_DIR.\n",
        "  -c CSV_PATH, --csv_path CSV_PATH\n",
        "                        Path of output .csv file. If none provided, then no file will be written.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import io\n",
        "import xml.etree.ElementTree as ET\n",
        "import argparse\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import tensorflow.compat.v1 as tf\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util, label_map_util\n",
        "from collections import namedtuple\n",
        "\n",
        "# Initiate argument parser\n",
        "parser = argparse.ArgumentParser(\n",
        "    description=\"Sample TensorFlow XML-to-TFRecord converter\")\n",
        "parser.add_argument(\"-x\",\n",
        "                    \"--xml_dir\",\n",
        "                    help=\"Path to the folder where the input .xml files are stored.\",\n",
        "                    type=str)\n",
        "parser.add_argument(\"-l\",\n",
        "                    \"--labels_path\",\n",
        "                    help=\"Path to the labels (.pbtxt) file.\", type=str)\n",
        "parser.add_argument(\"-o\",\n",
        "                    \"--output_path\",\n",
        "                    help=\"Path of output TFRecord (.record) file.\", type=str)\n",
        "parser.add_argument(\"-i\",\n",
        "                    \"--image_dir\",\n",
        "                    help=\"Path to the folder where the input image files are stored. \"\n",
        "                         \"Defaults to the same directory as XML_DIR.\",\n",
        "                    type=str, default=None)\n",
        "parser.add_argument(\"-c\",\n",
        "                    \"--csv_path\",\n",
        "                    help=\"Path of output .csv file. If none provided, then no file will be \"\n",
        "                         \"written.\",\n",
        "                    type=str, default=None)\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "if args.image_dir is None:\n",
        "    args.image_dir = args.xml_dir\n",
        "\n",
        "label_map = label_map_util.load_labelmap(args.labels_path)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map)\n",
        "\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    \"\"\"Iterates through all .xml files (generated by labelImg) in a given directory and combines\n",
        "    them in a single Pandas dataframe.\n",
        "    Parameters:\n",
        "    ----------\n",
        "    path : str\n",
        "        The path containing the .xml files\n",
        "    Returns\n",
        "    -------\n",
        "    Pandas DataFrame\n",
        "        The produced dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height',\n",
        "                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "    return label_map_dict[row_label]\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "\n",
        "    writer = tf.python_io.TFRecordWriter(args.output_path)\n",
        "    path = os.path.join(args.image_dir)\n",
        "    examples = xml_to_csv(args.xml_dir)\n",
        "    grouped = split(examples, 'filename')\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "    writer.close()\n",
        "    print('Successfully created the TFRecord file: {}'.format(args.output_path))\n",
        "    if args.csv_path is not None:\n",
        "        examples.to_csv(args.csv_path, index=None)\n",
        "        print('Successfully created the CSV file: {}'.format(args.csv_path))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing RealTimeObjectDetection/scripts/generate_tfrecord.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_mDL8Hw3Yae"
      },
      "source": [
        "labels = [{'name':'mochi', 'id':1},\n",
        "          {'name':'bottle', 'id':2},\n",
        "          {'name':'controller', 'id':3},\n",
        "          {'name':'remote', 'id':4},\n",
        "          {'name':'sunglasses', 'id':5}]\n",
        "\n",
        "with open(ANNOTATION_PATH + '/label_map.pbtxt', 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHYKx2EezF_0"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+'/label_map.pbtxt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0_7Wku7x4Qb",
        "outputId": "45e88322-6f02-48c6-95ef-006b21bcc123"
      },
      "source": [
        "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/train'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/train.record'}\n",
        "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/test'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/test.record'}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: RealTimeObjectDetection/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: RealTimeObjectDetection/workspace/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou6F6c4SPFD-"
      },
      "source": [
        "# Change pipeline.config for custom tranning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlqqv71CPk0e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from object_detection.utils import config_util\n",
        "from google.protobuf import text_format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1rZtgrRs2-V"
      },
      "source": [
        "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxHbbogVvOcq"
      },
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WdKsEjRvwGl"
      },
      "source": [
        "pipeline_config.model.faster_rcnn.num_classes = 5\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = CUSTOM_MODEL_PATH +'/checkpointPretrain/ckpt-0'\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= ANNOTATION_PATH + '/label_map.pbtxt'\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/train.record']\n",
        "pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/test.record']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljfIXD5wy-Bu"
      },
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(CONFIG_PATH,'wb') as f:\n",
        "    f.write(config_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NobCslcXxAHx"
      },
      "source": [
        "#rename checkpoint folder for not getting error checkpoint is a directory\n",
        "!mv /content/RealTimeObjectDetection/workspace/models/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint /content/RealTimeObjectDetection/workspace/models/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpointPretrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB7zjIzS7_Zo"
      },
      "source": [
        "# Tranning model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2-3C0pq2AZ1",
        "outputId": "5ff5e540-2384-4444-bea9-8611d49b9aa9"
      },
      "source": [
        "!python $APIMODEL_PATH/research/object_detection/model_main_tf2.py \\\n",
        "--model_dir=$CUSTOM_MODEL_PATH \\\n",
        "--pipeline_config_path=$CUSTOM_MODEL_PATH/pipeline.config \\\n",
        "--num_train_steps=5000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 04:29:52.864874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-16 04:29:55.117244: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-16 04:29:55.119507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-16 04:29:55.175991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 04:29:55.176567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-04-16 04:29:55.176603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-16 04:29:55.251867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-16 04:29:55.251977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-04-16 04:29:55.396214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-16 04:29:55.442230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-16 04:29:55.683505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-16 04:29:55.742413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-04-16 04:29:55.746234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-04-16 04:29:55.746374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 04:29:55.747041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 04:29:55.747603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-16 04:29:55.747965: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-04-16 04:29:55.748079: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-16 04:29:55.748191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 04:29:55.748726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-04-16 04:29:55.748755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-16 04:29:55.748800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-16 04:29:55.748823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-04-16 04:29:55.748842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-16 04:29:55.748875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-16 04:29:55.748898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-16 04:29:55.748930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-04-16 04:29:55.748951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-04-16 04:29:55.749020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 04:29:55.749576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 04:29:55.750106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-16 04:29:55.750150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-16 04:29:56.351219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-16 04:29:56.351270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-04-16 04:29:56.351283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-04-16 04:29:56.351499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 04:29:56.352172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 04:29:56.352766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 04:29:56.353296: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-16 04:29:56.353357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13968 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0416 04:29:56.355273 140289315514240 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0416 04:29:56.359236 140289315514240 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0416 04:29:56.359410 140289315514240 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:546: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0416 04:29:56.483005 140289315514240 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:546: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['RealTimeObjectDetection/workspace/annotations/train.record']\n",
            "I0416 04:29:56.487065 140289315514240 dataset_builder.py:163] Reading unweighted datasets: ['RealTimeObjectDetection/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['RealTimeObjectDetection/workspace/annotations/train.record']\n",
            "I0416 04:29:56.487244 140289315514240 dataset_builder.py:80] Reading record datasets for input file: ['RealTimeObjectDetection/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0416 04:29:56.487328 140289315514240 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0416 04:29:56.487405 140289315514240 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0416 04:29:56.489324 140289315514240 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0416 04:29:56.505057 140289315514240 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0416 04:30:03.038784 140289315514240 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0416 04:30:05.807144 140289315514240 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-04-16 04:30:08.378948: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-04-16 04:30:08.385278: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "2021-04-16 04:30:10.328073: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 85821696 exceeds 10% of free system memory.\n",
            "2021-04-16 04:30:10.441057: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 85821696 exceeds 10% of free system memory.\n",
            "2021-04-16 04:30:10.483661: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 146313216 exceeds 10% of free system memory.\n",
            "2021-04-16 04:30:10.581564: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 82301184 exceeds 10% of free system memory.\n",
            "2021-04-16 04:30:10.641999: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 82301184 exceeds 10% of free system memory.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0416 04:30:18.858395 140285819168512 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/utils/model_util.py:57: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "W0416 04:30:26.383545 140285819168512 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/utils/model_util.py:57: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0416 04:30:31.257588 140285819168512 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "2021-04-16 04:30:45.299949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-16 04:30:47.817350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-04-16 04:30:47.840978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists\n",
            "W0416 04:31:22.807052 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._groundtruth_lists\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv\n",
            "W0416 04:31:22.807358 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor\n",
            "W0416 04:31:22.807441 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._maxpool_layer\n",
            "W0416 04:31:22.807520 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._maxpool_layer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor\n",
            "W0416 04:31:22.807588 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n",
            "W0416 04:31:22.807651 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.endpoints\n",
            "W0416 04:31:22.807715 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model.endpoints\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0\n",
            "W0416 04:31:22.807779 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1\n",
            "W0416 04:31:22.807842 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2\n",
            "W0416 04:31:22.807904 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads\n",
            "W0416 04:31:22.807979 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._sorted_head_names\n",
            "W0416 04:31:22.808041 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._sorted_head_names\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets\n",
            "W0416 04:31:22.808103 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head\n",
            "W0416 04:31:22.808165 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head\n",
            "W0416 04:31:22.808227 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._third_stage_heads\n",
            "W0416 04:31:22.808290 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._third_stage_heads\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0._inbound_nodes\n",
            "W0416 04:31:22.808366 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0._inbound_nodes\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.kernel\n",
            "W0416 04:31:22.808444 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.bias\n",
            "W0416 04:31:22.808514 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1._inbound_nodes\n",
            "W0416 04:31:22.808577 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1._inbound_nodes\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2._inbound_nodes\n",
            "W0416 04:31:22.808639 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2._inbound_nodes\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings\n",
            "W0416 04:31:22.808702 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background\n",
            "W0416 04:31:22.808764 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets.0\n",
            "W0416 04:31:22.808826 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers\n",
            "W0416 04:31:22.808888 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers\n",
            "W0416 04:31:22.808966 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0\n",
            "W0416 04:31:22.809071 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0\n",
            "W0416 04:31:22.809139 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.0\n",
            "W0416 04:31:22.809203 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1\n",
            "W0416 04:31:22.809266 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.2\n",
            "W0416 04:31:22.809329 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.0\n",
            "W0416 04:31:22.809391 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1\n",
            "W0416 04:31:22.809459 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.2\n",
            "W0416 04:31:22.809521 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers\n",
            "W0416 04:31:22.809583 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers\n",
            "W0416 04:31:22.809646 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.kernel\n",
            "W0416 04:31:22.809710 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.bias\n",
            "W0416 04:31:22.809773 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.kernel\n",
            "W0416 04:31:22.809835 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.bias\n",
            "W0416 04:31:22.809897 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0\n",
            "W0416 04:31:22.809970 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0\n",
            "W0416 04:31:22.810034 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.kernel\n",
            "W0416 04:31:22.810097 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.bias\n",
            "W0416 04:31:22.810159 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.kernel\n",
            "W0416 04:31:22.810221 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.bias\n",
            "W0416 04:31:22.810284 140289315514240 util.py:161] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "W0416 04:31:22.810350 140289315514240 util.py:169] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0416 04:31:23.153599 140289315514240 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0416 04:31:23.154756 140289315514240 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0416 04:31:23.156629 140289315514240 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0416 04:31:23.157425 140289315514240 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0416 04:31:23.159273 140289315514240 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0416 04:31:23.160067 140289315514240 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0416 04:31:23.162235 140289315514240 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0416 04:31:23.163026 140289315514240 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0416 04:31:23.165185 140289315514240 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0416 04:31:23.165971 140289315514240 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0416 04:31:31.645676 140285819168512 deprecation.py:537] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 0.734s loss=0.267\n",
            "I0416 04:33:10.320635 140289315514240 model_lib_v2.py:682] Step 100 per-step time 0.734s loss=0.267\n",
            "INFO:tensorflow:Step 200 per-step time 0.746s loss=0.263\n",
            "I0416 04:34:22.886835 140289315514240 model_lib_v2.py:682] Step 200 per-step time 0.746s loss=0.263\n",
            "INFO:tensorflow:Step 300 per-step time 0.721s loss=0.165\n",
            "I0416 04:35:35.313539 140289315514240 model_lib_v2.py:682] Step 300 per-step time 0.721s loss=0.165\n",
            "INFO:tensorflow:Step 400 per-step time 0.722s loss=0.163\n",
            "I0416 04:36:48.942950 140289315514240 model_lib_v2.py:682] Step 400 per-step time 0.722s loss=0.163\n",
            "INFO:tensorflow:Step 500 per-step time 0.773s loss=0.068\n",
            "I0416 04:38:02.049539 140289315514240 model_lib_v2.py:682] Step 500 per-step time 0.773s loss=0.068\n",
            "INFO:tensorflow:Step 600 per-step time 0.741s loss=0.285\n",
            "I0416 04:39:16.051156 140289315514240 model_lib_v2.py:682] Step 600 per-step time 0.741s loss=0.285\n",
            "INFO:tensorflow:Step 700 per-step time 0.743s loss=0.084\n",
            "I0416 04:40:30.489260 140289315514240 model_lib_v2.py:682] Step 700 per-step time 0.743s loss=0.084\n",
            "INFO:tensorflow:Step 800 per-step time 0.716s loss=0.065\n",
            "I0416 04:41:44.094395 140289315514240 model_lib_v2.py:682] Step 800 per-step time 0.716s loss=0.065\n",
            "INFO:tensorflow:Step 900 per-step time 0.736s loss=0.055\n",
            "I0416 04:42:58.619933 140289315514240 model_lib_v2.py:682] Step 900 per-step time 0.736s loss=0.055\n",
            "INFO:tensorflow:Step 1000 per-step time 0.681s loss=0.086\n",
            "I0416 04:44:12.256029 140289315514240 model_lib_v2.py:682] Step 1000 per-step time 0.681s loss=0.086\n",
            "INFO:tensorflow:Step 1100 per-step time 0.814s loss=0.086\n",
            "I0416 04:45:26.190553 140289315514240 model_lib_v2.py:682] Step 1100 per-step time 0.814s loss=0.086\n",
            "INFO:tensorflow:Step 1200 per-step time 0.777s loss=0.070\n",
            "I0416 04:46:39.496689 140289315514240 model_lib_v2.py:682] Step 1200 per-step time 0.777s loss=0.070\n",
            "INFO:tensorflow:Step 1300 per-step time 0.724s loss=0.090\n",
            "I0416 04:47:52.867162 140289315514240 model_lib_v2.py:682] Step 1300 per-step time 0.724s loss=0.090\n",
            "INFO:tensorflow:Step 1400 per-step time 0.712s loss=0.047\n",
            "I0416 04:49:06.823820 140289315514240 model_lib_v2.py:682] Step 1400 per-step time 0.712s loss=0.047\n",
            "INFO:tensorflow:Step 1500 per-step time 0.714s loss=0.061\n",
            "I0416 04:50:20.832469 140289315514240 model_lib_v2.py:682] Step 1500 per-step time 0.714s loss=0.061\n",
            "INFO:tensorflow:Step 1600 per-step time 0.780s loss=0.033\n",
            "I0416 04:51:34.986920 140289315514240 model_lib_v2.py:682] Step 1600 per-step time 0.780s loss=0.033\n",
            "INFO:tensorflow:Step 1700 per-step time 0.742s loss=0.074\n",
            "I0416 04:52:47.865230 140289315514240 model_lib_v2.py:682] Step 1700 per-step time 0.742s loss=0.074\n",
            "INFO:tensorflow:Step 1800 per-step time 0.759s loss=0.095\n",
            "I0416 04:54:01.508632 140289315514240 model_lib_v2.py:682] Step 1800 per-step time 0.759s loss=0.095\n",
            "INFO:tensorflow:Step 1900 per-step time 0.723s loss=0.061\n",
            "I0416 04:55:15.877159 140289315514240 model_lib_v2.py:682] Step 1900 per-step time 0.723s loss=0.061\n",
            "INFO:tensorflow:Step 2000 per-step time 0.764s loss=0.033\n",
            "I0416 04:56:30.588541 140289315514240 model_lib_v2.py:682] Step 2000 per-step time 0.764s loss=0.033\n",
            "INFO:tensorflow:Step 2100 per-step time 0.699s loss=0.028\n",
            "I0416 04:57:44.420756 140289315514240 model_lib_v2.py:682] Step 2100 per-step time 0.699s loss=0.028\n",
            "INFO:tensorflow:Step 2200 per-step time 0.729s loss=0.057\n",
            "I0416 04:58:58.341802 140289315514240 model_lib_v2.py:682] Step 2200 per-step time 0.729s loss=0.057\n",
            "INFO:tensorflow:Step 2300 per-step time 0.767s loss=0.046\n",
            "I0416 05:00:12.590582 140289315514240 model_lib_v2.py:682] Step 2300 per-step time 0.767s loss=0.046\n",
            "INFO:tensorflow:Step 2400 per-step time 0.781s loss=0.124\n",
            "I0416 05:01:25.939307 140289315514240 model_lib_v2.py:682] Step 2400 per-step time 0.781s loss=0.124\n",
            "INFO:tensorflow:Step 2500 per-step time 0.743s loss=0.041\n",
            "I0416 05:02:38.924785 140289315514240 model_lib_v2.py:682] Step 2500 per-step time 0.743s loss=0.041\n",
            "INFO:tensorflow:Step 2600 per-step time 0.698s loss=0.048\n",
            "I0416 05:03:53.005016 140289315514240 model_lib_v2.py:682] Step 2600 per-step time 0.698s loss=0.048\n",
            "INFO:tensorflow:Step 2700 per-step time 0.693s loss=0.076\n",
            "I0416 05:05:05.898355 140289315514240 model_lib_v2.py:682] Step 2700 per-step time 0.693s loss=0.076\n",
            "INFO:tensorflow:Step 2800 per-step time 0.726s loss=0.045\n",
            "I0416 05:06:19.648291 140289315514240 model_lib_v2.py:682] Step 2800 per-step time 0.726s loss=0.045\n",
            "INFO:tensorflow:Step 2900 per-step time 0.711s loss=0.052\n",
            "I0416 05:07:33.021802 140289315514240 model_lib_v2.py:682] Step 2900 per-step time 0.711s loss=0.052\n",
            "INFO:tensorflow:Step 3000 per-step time 0.717s loss=0.023\n",
            "I0416 05:08:46.394936 140289315514240 model_lib_v2.py:682] Step 3000 per-step time 0.717s loss=0.023\n",
            "INFO:tensorflow:Step 3100 per-step time 0.712s loss=0.022\n",
            "I0416 05:10:00.984562 140289315514240 model_lib_v2.py:682] Step 3100 per-step time 0.712s loss=0.022\n",
            "INFO:tensorflow:Step 3200 per-step time 0.689s loss=0.021\n",
            "I0416 05:11:15.420368 140289315514240 model_lib_v2.py:682] Step 3200 per-step time 0.689s loss=0.021\n",
            "INFO:tensorflow:Step 3300 per-step time 0.756s loss=0.024\n",
            "I0416 05:12:28.662049 140289315514240 model_lib_v2.py:682] Step 3300 per-step time 0.756s loss=0.024\n",
            "INFO:tensorflow:Step 3400 per-step time 0.793s loss=0.031\n",
            "I0416 05:13:42.773019 140289315514240 model_lib_v2.py:682] Step 3400 per-step time 0.793s loss=0.031\n",
            "INFO:tensorflow:Step 3500 per-step time 0.796s loss=0.027\n",
            "I0416 05:14:56.616878 140289315514240 model_lib_v2.py:682] Step 3500 per-step time 0.796s loss=0.027\n",
            "INFO:tensorflow:Step 3600 per-step time 0.839s loss=0.023\n",
            "I0416 05:16:10.364107 140289315514240 model_lib_v2.py:682] Step 3600 per-step time 0.839s loss=0.023\n",
            "INFO:tensorflow:Step 3700 per-step time 0.743s loss=0.037\n",
            "I0416 05:17:24.011274 140289315514240 model_lib_v2.py:682] Step 3700 per-step time 0.743s loss=0.037\n",
            "INFO:tensorflow:Step 3800 per-step time 0.640s loss=0.010\n",
            "I0416 05:18:37.580416 140289315514240 model_lib_v2.py:682] Step 3800 per-step time 0.640s loss=0.010\n",
            "INFO:tensorflow:Step 3900 per-step time 0.821s loss=0.051\n",
            "I0416 05:19:50.704607 140289315514240 model_lib_v2.py:682] Step 3900 per-step time 0.821s loss=0.051\n",
            "INFO:tensorflow:Step 4000 per-step time 0.779s loss=0.018\n",
            "I0416 05:21:04.207566 140289315514240 model_lib_v2.py:682] Step 4000 per-step time 0.779s loss=0.018\n",
            "INFO:tensorflow:Step 4100 per-step time 0.696s loss=0.032\n",
            "I0416 05:22:18.173561 140289315514240 model_lib_v2.py:682] Step 4100 per-step time 0.696s loss=0.032\n",
            "INFO:tensorflow:Step 4200 per-step time 0.749s loss=0.023\n",
            "I0416 05:23:31.033921 140289315514240 model_lib_v2.py:682] Step 4200 per-step time 0.749s loss=0.023\n",
            "INFO:tensorflow:Step 4300 per-step time 0.719s loss=0.022\n",
            "I0416 05:24:44.369640 140289315514240 model_lib_v2.py:682] Step 4300 per-step time 0.719s loss=0.022\n",
            "INFO:tensorflow:Step 4400 per-step time 0.740s loss=0.034\n",
            "I0416 05:25:57.731405 140289315514240 model_lib_v2.py:682] Step 4400 per-step time 0.740s loss=0.034\n",
            "INFO:tensorflow:Step 4500 per-step time 0.743s loss=0.023\n",
            "I0416 05:27:11.526158 140289315514240 model_lib_v2.py:682] Step 4500 per-step time 0.743s loss=0.023\n",
            "INFO:tensorflow:Step 4600 per-step time 0.700s loss=0.008\n",
            "I0416 05:28:25.799298 140289315514240 model_lib_v2.py:682] Step 4600 per-step time 0.700s loss=0.008\n",
            "INFO:tensorflow:Step 4700 per-step time 0.733s loss=0.046\n",
            "I0416 05:29:39.796589 140289315514240 model_lib_v2.py:682] Step 4700 per-step time 0.733s loss=0.046\n",
            "INFO:tensorflow:Step 4800 per-step time 0.745s loss=0.013\n",
            "I0416 05:30:53.427976 140289315514240 model_lib_v2.py:682] Step 4800 per-step time 0.745s loss=0.013\n",
            "INFO:tensorflow:Step 4900 per-step time 0.784s loss=0.032\n",
            "I0416 05:32:07.012551 140289315514240 model_lib_v2.py:682] Step 4900 per-step time 0.784s loss=0.032\n",
            "INFO:tensorflow:Step 5000 per-step time 0.668s loss=0.014\n",
            "I0416 05:33:20.027734 140289315514240 model_lib_v2.py:682] Step 5000 per-step time 0.668s loss=0.014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gziRIHXZ4sMl"
      },
      "source": [
        "### Create function to use webcam in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hQbCI_M4ET2"
      },
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'Bấm vào video để dừng</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LCoLnrw4SWF"
      },
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrImKYwO4viu"
      },
      "source": [
        "### Create model and function for get bbox predict and object predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdJwY4BF03vP"
      },
      "source": [
        "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-6')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9T6Qe0kRnEI"
      },
      "source": [
        "import collections\n",
        "# Set headless-friendly backend.\n",
        "STANDARD_COLORS = [\n",
        "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n",
        "    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
        "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n",
        "    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
        "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
        "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
        "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n",
        "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
        "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
        "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
        "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
        "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
        "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
        "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
        "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
        "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
        "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
        "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
        "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown',\n",
        "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
        "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
        "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
        "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
        "]\n",
        "def visualize_boxes_and_labels_on_image_array(\n",
        "    image,\n",
        "    boxes,\n",
        "    classes,\n",
        "    scores,\n",
        "    category_index,\n",
        "    max_boxes_to_draw=20,\n",
        "    min_score_thresh=.5,):\n",
        "\n",
        "  # Create a display string (and color) for every box location, group any boxes\n",
        "  # that correspond to the same location.\n",
        "  bbox_predicts=[]\n",
        "  box_to_color_map = collections.defaultdict(str)\n",
        "  if not max_boxes_to_draw:\n",
        "    max_boxes_to_draw = boxes.shape[0]\n",
        "  for i in range(boxes.shape[0]):\n",
        "    if max_boxes_to_draw == len(box_to_color_map):\n",
        "      break\n",
        "    if scores is None or scores[i] > min_score_thresh:\n",
        "      bbox_object = {}\n",
        "      bbox_object['bbox'] = tuple(boxes[i].tolist())\n",
        "\n",
        "      class_name = 'N/A'\n",
        "      if classes[i] in six.viewkeys(category_index):\n",
        "        class_name = category_index[classes[i]]['name']\n",
        "      bbox_object['class_name'] = class_name\n",
        "\n",
        "      score = round(100*scores[i])\n",
        "      bbox_object['score'] = score\n",
        "\n",
        "      color = STANDARD_COLORS[classes[i] % len(STANDARD_COLORS)]\n",
        "      bbox_object['color'] = color\n",
        "      bbox_predicts.append(bbox_object)\n",
        "  return bbox_predicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHv8ScIg_lgN"
      },
      "source": [
        "#Real time object detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jctHEPEPN8Je"
      },
      "source": [
        "from google.colab.output import eval_js\n",
        "import matplotlib.pyplot as plt\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL\n",
        "import io\n",
        "import cv2\n",
        "import numpy as np\n",
        "import six"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1bQV2162Pvv"
      },
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "while True: \n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "  \n",
        "    image_np = np.array(js_to_image(js_reply[\"img\"]))\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "    bbox_predicts = visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.9)\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "    im_width = 640\n",
        "    im_height = 480\n",
        "    for predict in bbox_predicts:\n",
        "        bbox_predict = predict.get('bbox')\n",
        "        ymin, xmin, ymax, xmax = bbox_predict\n",
        "        xmin, xmax, ymin,ymax  = (int(xmin * im_width), int(xmax * im_width),\n",
        "                                  int(ymin * im_height), int(ymax * im_height))\n",
        "        class_name = predict.get('class_name')\n",
        "        score = predict.get('score')\n",
        "        color = predict.get('color')\n",
        "        bbox_array = cv2.rectangle(bbox_array, tuple((xmin,ymin)), \n",
        "          tuple((xmax,ymax)), (0, 255, 0), 2)\n",
        "        bbox_array = cv2.putText(bbox_array, \"{}:{}\".format(class_name,score),\n",
        "                            (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFPYswRfbu_G"
      },
      "source": [
        "# Authors: Tran Phuong Nam\n",
        "\n",
        "Facebook: https://www.facebook.com/namphuongtran9196/\n",
        "\n",
        "Github: https://github.com/namphuongtran9196\n",
        "\n",
        "Linkedln: https://www.linkedin.com/in/namtranphuong9196/"
      ]
    }
  ]
}
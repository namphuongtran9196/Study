{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import tqdm\n",
    "import shutil\n",
    "import xmltodict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"train_dataset\")\n",
    "os.mkdir(\"train_dataset/images\")\n",
    "os.mkdir(\"train_dataset/labels\")\n",
    "output_dataset_path = \"train_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Priv_personpart/ImageSets/privpersonpart_train_im2xml.txt\") as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [01:19<00:00, 151.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(len(data))):\n",
    "    img_path = data[i].split(\" \")[0]\n",
    "    label_path = data[i].split(\" \")[1].strip()\n",
    "    with open(\"Priv_personpart\" + label_path) as xml_file:\n",
    "        data_dict = xmltodict.parse(xml_file.read())\n",
    "    has_hand = False\n",
    "    with open(os.path.join(output_dataset_path, \"labels\",data_dict['annotation']['filename'] + '.txt'), 'w') as writer:\n",
    "        img = cv2.imread(\"Priv_personpart\" + img_path)\n",
    "        with open(\"Priv_personpart\" + label_path) as xml_file:\n",
    "            if isinstance(data_dict['annotation']['object'], dict):\n",
    "                ano = data_dict['annotation']['object']\n",
    "                if ano['name'] == 'hand':\n",
    "                    has_hand = True\n",
    "                    xmin = int(ano['bndbox']['xmin'])\n",
    "                    ymin = int(ano['bndbox']['ymin'])\n",
    "                    xmax = int(ano['bndbox']['xmax'])\n",
    "                    ymax = int(ano['bndbox']['ymax'])\n",
    "                    \n",
    "                    x_center = (xmin + xmax) / 2\n",
    "                    y_center = (ymin + ymax) / 2\n",
    "                    width = xmax - xmin\n",
    "                    height = ymax - ymin\n",
    "                    \n",
    "                    x_center = x_center / img.shape[1]\n",
    "                    y_center = y_center / img.shape[0]\n",
    "                    width = width / img.shape[1]\n",
    "                    height = height / img.shape[0]\n",
    "                    writer.write(\"0 {:.6f} {:.6f} {:.6f} {:.6f}\\n\".format(x_center, y_center, width, height))\n",
    "            else:\n",
    "                for ano in data_dict['annotation']['object']:\n",
    "                    if ano['name'] == 'hand':\n",
    "                        has_hand = True\n",
    "                        xmin = int(ano['bndbox']['xmin'])\n",
    "                        ymin = int(ano['bndbox']['ymin'])\n",
    "                        xmax = int(ano['bndbox']['xmax'])\n",
    "                        ymax = int(ano['bndbox']['ymax'])\n",
    "                        \n",
    "                        x_center = (xmin + xmax) / 2\n",
    "                        y_center = (ymin + ymax) / 2\n",
    "                        width = xmax - xmin\n",
    "                        height = ymax - ymin\n",
    "                        \n",
    "                        x_center = x_center / img.shape[1]\n",
    "                        y_center = y_center / img.shape[0]\n",
    "                        width = width / img.shape[1]\n",
    "                        height = height / img.shape[0]\n",
    "                        writer.write(\"0 {:.6f} {:.6f} {:.6f} {:.6f}\\n\".format(x_center, y_center, width, height))\n",
    "    if has_hand:\n",
    "        shutil.copy(\"Priv_personpart\" + img_path, os.path.join(output_dataset_path, \"images\", data_dict['annotation']['filename'] + '.jpg'))\n",
    "    else:\n",
    "        os.remove(os.path.join(output_dataset_path, \"labels\",data_dict['annotation']['filename'] + '.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"val_dataset\")\n",
    "os.mkdir(\"val_dataset/images\")\n",
    "os.mkdir(\"val_dataset/labels\")\n",
    "output_dataset_path = \"val_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Priv_personpart/ImageSets/privpersonpart_val_im2xml.txt\") as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2962/2962 [00:19<00:00, 149.20it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(len(data))):\n",
    "    img_path = data[i].split(\" \")[0]\n",
    "    label_path = data[i].split(\" \")[1].strip()\n",
    "    with open(\"Priv_personpart\" + label_path) as xml_file:\n",
    "        data_dict = xmltodict.parse(xml_file.read())\n",
    "    has_hand = False\n",
    "    with open(os.path.join(output_dataset_path, \"labels\",data_dict['annotation']['filename'] + '.txt'), 'w') as writer:\n",
    "        img = cv2.imread(\"Priv_personpart\" + img_path)\n",
    "        with open(\"Priv_personpart\" + label_path) as xml_file:\n",
    "            if isinstance(data_dict['annotation']['object'], dict):\n",
    "                ano = data_dict['annotation']['object']\n",
    "                if ano['name'] == 'hand':\n",
    "                    has_hand = True\n",
    "                    xmin = int(ano['bndbox']['xmin'])\n",
    "                    ymin = int(ano['bndbox']['ymin'])\n",
    "                    xmax = int(ano['bndbox']['xmax'])\n",
    "                    ymax = int(ano['bndbox']['ymax'])\n",
    "                    \n",
    "                    x_center = (xmin + xmax) / 2\n",
    "                    y_center = (ymin + ymax) / 2\n",
    "                    width = xmax - xmin\n",
    "                    height = ymax - ymin\n",
    "                    \n",
    "                    x_center = x_center / img.shape[1]\n",
    "                    y_center = y_center / img.shape[0]\n",
    "                    width = width / img.shape[1]\n",
    "                    height = height / img.shape[0]\n",
    "                    writer.write(\"0 {:.6f} {:.6f} {:.6f} {:.6f}\\n\".format(x_center, y_center, width, height))\n",
    "            else:\n",
    "                for ano in data_dict['annotation']['object']:\n",
    "                    if ano['name'] == 'hand':\n",
    "                        has_hand = True\n",
    "                        xmin = int(ano['bndbox']['xmin'])\n",
    "                        ymin = int(ano['bndbox']['ymin'])\n",
    "                        xmax = int(ano['bndbox']['xmax'])\n",
    "                        ymax = int(ano['bndbox']['ymax'])\n",
    "                        \n",
    "                        x_center = (xmin + xmax) / 2\n",
    "                        y_center = (ymin + ymax) / 2\n",
    "                        width = xmax - xmin\n",
    "                        height = ymax - ymin\n",
    "                        \n",
    "                        x_center = x_center / img.shape[1]\n",
    "                        y_center = y_center / img.shape[0]\n",
    "                        width = width / img.shape[1]\n",
    "                        height = height / img.shape[0]\n",
    "                        writer.write(\"0 {:.6f} {:.6f} {:.6f} {:.6f}\\n\".format(x_center, y_center, width, height))\n",
    "    if has_hand:\n",
    "        shutil.copy(\"Priv_personpart\" + img_path, os.path.join(output_dataset_path, \"images\", data_dict['annotation']['filename'] + '.jpg'))\n",
    "    else:\n",
    "        os.remove(os.path.join(output_dataset_path, \"labels\",data_dict['annotation']['filename'] + '.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11513\n",
      "2821\n",
      "11513\n",
      "2821\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(len(glob.glob(\"train_dataset/images/*.jpg\")))\n",
    "print(len(glob.glob(\"val_dataset/images/*.jpg\")))\n",
    "print(len(glob.glob(\"train_dataset/labels/*.txt\")))\n",
    "print(len(glob.glob(\"val_dataset/labels/*.txt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir custom_dataset\n",
    "!mv train_dataset custom_dataset\n",
    "!mv val_dataset custom_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('custom_dataset/custom_dataset.yaml', 'w') as f:\n",
    "    f.write(\n",
    "    \"\"\"# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
    "path: custom_dataset  # dataset root dir\n",
    "train: train_dataset/images  # train images (relative to 'path') 128 images\n",
    "val: val_dataset/images  # val images (relative to 'path') 128 images\n",
    "test:  # test images (optional)\n",
    "\n",
    "# Classes (80 COCO classes)\n",
    "names:\n",
    "    0: hand\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('minami')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9ff0bd1e9369fb2e4b99c8ce582220089c0804671049193be6eafcbdf5f5aa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
